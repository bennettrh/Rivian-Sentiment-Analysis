{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_news(apiKey: str, ticker: str, startDate: str, endDate: str):\n",
    "    \"\"\"\n",
    "    Requests financial news for a specific company within a specific date range from the Finnhub API.\n",
    "\n",
    "    Args:\n",
    "        apiKey: Your Finnhub API Key\n",
    "        ticker: The Ticker symbol for the stock yo are interested in\n",
    "        startDate: the start date for the date range, formatted YYYY-MM-DD\n",
    "        endDate: the end date for the date range, formatted YYYY-MM-DD \n",
    "\n",
    "    Returns response json if successful\n",
    "    \"\"\"\n",
    "    baseurl = 'https://finnhub.io/api/v1/company-news?'\n",
    "    url = f'{baseurl}symbol={ticker}&from={startDate}&to={endDate}&token={apiKey}'\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def parse(response: list):\n",
    "    \"\"\"\n",
    "    Parses the JSON response into a Pandas Dataframe \n",
    "\n",
    "    Args:\n",
    "        response: The JSON response containing company news information from the FinnHub API \n",
    "\n",
    "    Returns Pandas DataFrame if successful\n",
    "    \"\"\"\n",
    "    results_dict = {\n",
    "        'id': [result['id'] for result in response],\n",
    "        'datetime': [result['datetime'] for result in response],\n",
    "        'source': [result['source'] for result in response],\n",
    "        'summary': [result['summary'] for result in response]\n",
    "    }\n",
    "    return pd.DataFrame(results_dict)\n",
    "\n",
    "## API will cut off number of results if time period is too long, perform separate request for each month\n",
    "\n",
    "api_key = 'Your API Key'\n",
    "ticker = 'RIVN'\n",
    "\n",
    "dates = [\n",
    "    ('2024-12-01', '2024-12-31'),\n",
    "    ('2024-11-01', '2024-11-30'),\n",
    "    ('2024-10-01', '2024-10-31'),\n",
    "    ('2024-09-01', '2024-09-30'),\n",
    "    ('2024-08-01', '2024-08-31'),\n",
    "    ('2024-07-01', '2024-07-31')\n",
    "    ]\n",
    "\n",
    "rivian_monthly_df = [parse(request_news(apiKey = api_key, ticker = ticker, startDate = start, endDate = end)) for start, end in dates]\n",
    "rivian_df = pd.concat(rivian_monthly_df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker = yf.Ticker('RIVN')\n",
    "\n",
    "historical = ticker.history(period='1y').reset_index()\n",
    "\n",
    "historical = historical.drop(['High', 'Low', 'Volume', 'Dividends', 'Stock Splits'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivian_df['datetime'] = pd.to_datetime(rivian_df['datetime'], unit = 's', utc = True).dt.tz_convert(\"America/New_York\")\n",
    "\n",
    "rivian_df = rivian_df[(rivian_df['source'].isin(['Yahoo'])) & (rivian_df['summary'] != '')]\n",
    "\n",
    "# Move date of articles published after market-close (4pm ET) one day forward given new sentiment after market close will only impact following day\n",
    "\n",
    "rivian_df.loc[rivian_df['datetime'].dt.hour >= 16, 'datetime'] = rivian_df.loc[rivian_df['datetime'].dt.hour >= 16, 'datetime'] + pd.Timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns and log overnight returns\n",
    "\n",
    "returns = [0]\n",
    "for i in range(1, len(historical['Close'])):\n",
    "    ret = np.log(historical['Close'][i]/historical['Close'][i-1])\n",
    "    returns.append(ret)\n",
    "\n",
    "overnight_returns = [0]\n",
    "for i in range(1, len(historical['Open'])):\n",
    "    ret = np.log(historical['Open'][i]/historical['Close'][i-1])\n",
    "    overnight_returns.append(ret)\n",
    "\n",
    "historical['Returns'] = returns\n",
    "historical['Overnight_Returns'] = overnight_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes and forward fill to account for articles published over weekends/holidays\n",
    "\n",
    "rivian_df['datetime'] = rivian_df['datetime'].dt.date\n",
    "historical['Date'] = historical['Date'].dt.date\n",
    "\n",
    "rivian_df = rivian_df.rename(columns={'datetime': 'Date'})\n",
    "\n",
    "rivian_df = pd.merge(rivian_df, historical, how = 'left', on = 'Date').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out responses with too many tokens for chosen model\n",
    "\n",
    "rivian_df['tokens'] = [len(nltk.word_tokenize(summary)) for summary in rivian_df['summary']]\n",
    "rivian_df = rivian_df[rivian_df['tokens'] <= 512].drop('tokens', axis = 1)\n",
    "\n",
    "## Perform analysis using finBERT model, store labels and scores as columns in original dataframe\n",
    "\n",
    "sent_pipeline = pipeline('sentiment-analysis', model = r'ProsusAI/finbert')\n",
    "\n",
    "sentiment_scores = [sent_pipeline(summary) for summary in rivian_df['summary']]\n",
    "\n",
    "rivian_df['sent_label'] = [label[0]['label'] for label in sentiment_scores]\n",
    "rivian_df['sent_score'] = [score[0]['score'] for score in sentiment_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivian_df.to_csv('CSVs/rivian_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical.to_csv('CSVs/historical.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
